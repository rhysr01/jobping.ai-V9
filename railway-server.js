#!/usr/bin/env node

/**
 * ðŸš‚ RAILWAY SCRAPER SERVICE
 * Enterprise-level scraper orchestration for JobPing
 * Integrates seamlessly with existing architecture
 */

require('dotenv').config();
const express = require('express');
const cron = require('node-cron');
const { spawn } = require('child_process');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Enhanced logging
const colors = {
  reset: '\x1b[0m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
  magenta: '\x1b[35m'
};

function log(message, color = 'reset') {
  const timestamp = new Date().toISOString();
  console.log(`${colors[color]}[${timestamp}] ${message}${colors.reset}`);
}

// Service state
let serviceState = {
  status: 'starting',
  uptime: Date.now(),
  lastScrape: null,
  totalScrapes: 0,
  successfulScrapes: 0,
  failedScrapes: 0,
  currentScrape: null
};

// Initialize your existing orchestrator
let orchestrator = null;

async function initializeOrchestrator() {
  try {
    // Import your existing ProductionScraperOrchestrator
    const { ProductionScraperOrchestrator } = require('./production-scraper');
    orchestrator = new ProductionScraperOrchestrator();
    
    // Log Railway configuration
    try {
      const { logConfig } = require('./Utils/railwayConfig');
      logConfig();
    } catch (configError) {
      log(`âš ï¸ Could not load Railway config: ${configError.message}`, 'yellow');
    }
    
    log('âœ… Production Scraper Orchestrator initialized', 'green');
    serviceState.status = 'ready';
  } catch (error) {
    log(`âŒ Failed to initialize orchestrator: ${error.message}`, 'red');
    log(`ðŸ”§ Attempting fallback initialization...`, 'yellow');
    
    // Fallback: Try to initialize with basic configuration
    try {
      const { ProductionScraperOrchestrator } = require('./production-scraper');
      orchestrator = new ProductionScraperOrchestrator();
      
      // Override configuration for Railway
      process.env.DISABLE_PUPPETEER = 'true';
      process.env.ENABLE_BROWSER_POOL = 'false';
      process.env.ENABLE_RATE_LIMITING = 'true';
      process.env.SCRAPER_REQUESTS_PER_MINUTE = '12';
      process.env.SCRAPER_REQUESTS_PER_HOUR = '360';
      
      log('âœ… Production Scraper Orchestrator initialized with Railway fallback', 'green');
      serviceState.status = 'ready';
    } catch (fallbackError) {
      log(`âŒ Fallback initialization also failed: ${fallbackError.message}`, 'red');
      serviceState.status = 'error';
    }
  }
}

// Health check endpoint
app.get('/health', (req, res) => {
  const uptime = Date.now() - serviceState.uptime;
  const uptimeMinutes = Math.floor(uptime / 60000);
  
  res.json({
    status: serviceState.status,
    service: 'jobping-railway-scrapers',
    uptime: `${uptimeMinutes} minutes`,
    lastScrape: serviceState.lastScrape,
    stats: {
      total: serviceState.totalScrapes,
      successful: serviceState.successfulScrapes,
      failed: serviceState.failedScrapes
    },
    timestamp: new Date().toISOString()
  });
});

// Manual scrape trigger
app.post('/scrape', async (req, res) => {
  log('ðŸš€ Manual scrape triggered', 'blue');
  
  if (serviceState.currentScrape) {
    return res.status(409).json({
      error: 'Scrape already in progress',
      currentScrape: serviceState.currentScrape
    });
  }

  try {
    serviceState.currentScrape = {
      id: Date.now().toString(),
      started: new Date().toISOString(),
      type: 'manual'
    };

    // Use your existing orchestrator
    if (orchestrator) {
      await orchestrator.runScrapingCycle();
    } else {
      // Fallback to direct script execution
      await runScrapingScript();
    }

    serviceState.totalScrapes++;
    serviceState.successfulScrapes++;
    serviceState.lastScrape = new Date().toISOString();
    
    res.json({
      success: true,
      message: 'Scraping completed successfully',
      scrapeId: serviceState.currentScrape.id,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    serviceState.totalScrapes++;
    serviceState.failedScrapes++;
    
    log(`âŒ Manual scrape failed: ${error.message}`, 'red');
    res.status(500).json({
      error: 'Scraping failed',
      message: error.message
    });
  } finally {
    serviceState.currentScrape = null;
  }
});

// Get scraping status
app.get('/status', async (req, res) => {
  // Get scraper rate limiting stats
  let rateLimitStats = {};
  try {
    const { productionRateLimiter } = require('./Utils/productionRateLimiter');
    rateLimitStats = productionRateLimiter.getScraperStats();
  } catch (error) {
    log('Failed to get rate limit stats: ' + error.message, 'yellow');
    rateLimitStats = { error: 'Stats unavailable' };
  }
  
  res.json({
    service: 'jobping-railway-scrapers',
    status: serviceState.status,
    currentScrape: serviceState.currentScrape,
    stats: {
      total: serviceState.totalScrapes,
      successful: serviceState.successfulScrapes,
      failed: serviceState.failedScrapes,
      successRate: serviceState.totalScrapes > 0 
        ? ((serviceState.successfulScrapes / serviceState.totalScrapes) * 100).toFixed(1) + '%'
        : '0%'
    },
    rateLimiting: rateLimitStats,
    uptime: Date.now() - serviceState.uptime,
    timestamp: new Date().toISOString()
  });
});

// Run scraping script (fallback method)
async function runScrapingScript() {
  return new Promise((resolve, reject) => {
    log('ðŸ”„ Running production scraper script...', 'cyan');
    
    const child = spawn('node', ['production-scraper.js', '--once'], {
      stdio: 'pipe',
      env: { ...process.env, NODE_ENV: 'production' }
    });

    let output = '';
    let errorOutput = '';

    child.stdout.on('data', (data) => {
      output += data.toString();
      log(`ðŸ“Š Scraper: ${data.toString().trim()}`, 'cyan');
    });

    child.stderr.on('data', (data) => {
      errorOutput += data.toString();
      log(`âš ï¸ Scraper Error: ${data.toString().trim()}`, 'yellow');
    });

    child.on('close', (code) => {
      if (code === 0) {
        log('âœ… Scraping script completed successfully', 'green');
        resolve();
      } else {
        log(`âŒ Scraping script failed with code ${code}`, 'red');
        reject(new Error(`Script failed with code ${code}: ${errorOutput}`));
      }
    });

    child.on('error', (error) => {
      log(`âŒ Failed to start scraping script: ${error.message}`, 'red');
      reject(error);
    });
  });
}

// Scheduled scraping using your existing orchestrator
async function runScheduledScrape() {
  if (serviceState.currentScrape) {
    log('â¸ï¸ Skipping scheduled scrape - one already in progress', 'yellow');
    return;
  }

  log('â° Running scheduled scrape...', 'blue');
  
  try {
    serviceState.currentScrape = {
      id: Date.now().toString(),
      started: new Date().toISOString(),
      type: 'scheduled'
    };

    if (orchestrator) {
      await orchestrator.runScrapingCycle();
    } else {
      await runScrapingScript();
    }

    serviceState.totalScrapes++;
    serviceState.successfulScrapes++;
    serviceState.lastScrape = new Date().toISOString();
    
    log('âœ… Scheduled scrape completed successfully', 'green');
  } catch (error) {
    serviceState.totalScrapes++;
    serviceState.failedScrapes++;
    
    log(`âŒ Scheduled scrape failed: ${error.message}`, 'red');
  } finally {
    serviceState.currentScrape = null;
  }
}

// Health check function
async function runHealthCheck() {
  try {
    log('ðŸ¥ Running health check...', 'cyan');
    
    const child = spawn('node', ['scripts/health-check.js'], {
      stdio: 'pipe',
      env: { ...process.env, NODE_ENV: 'production' }
    });

    child.stdout.on('data', (data) => {
      log(`ðŸ¥ Health: ${data.toString().trim()}`, 'cyan');
    });

    child.stderr.on('data', (data) => {
      log(`âš ï¸ Health Error: ${data.toString().trim()}`, 'yellow');
    });

    child.on('close', (code) => {
      if (code === 0) {
        log('âœ… Health check completed', 'green');
      } else {
        log(`âŒ Health check failed with code ${code}`, 'red');
      }
    });
  } catch (error) {
    log(`âŒ Health check error: ${error.message}`, 'red');
  }
}

// Initialize service
async function initializeService() {
  log('ðŸš‚ Initializing JobPing Railway Scraper Service...', 'blue');
  
  // Initialize orchestrator
  await initializeOrchestrator();
  
  // Schedule scrapes every hour
  cron.schedule('0 * * * *', runScheduledScrape);
  log('â° Scheduled scraping every hour (0 * * * *)', 'green');
  
  // Health checks every 5 minutes
  cron.schedule('*/5 * * * *', runHealthCheck);
  log('ðŸ¥ Health checks every 5 minutes', 'green');
  
  // Run initial health check
  setTimeout(runHealthCheck, 10000); // 10 seconds after startup
  
  log('âœ… Railway scraper service initialized successfully', 'green');
}

// Start server
app.listen(PORT, () => {
  log(`ðŸš‚ Railway scraper service running on port ${PORT}`, 'green');
  log(`ðŸ¥ Health check: http://localhost:${PORT}/health`, 'cyan');
  log(`ðŸŽ¯ Manual scrape: POST http://localhost:${PORT}/scrape`, 'cyan');
  log(`ðŸ“Š Status: GET http://localhost:${PORT}/status`, 'cyan');
  
  // Initialize service after server starts
  initializeService();
});

// Graceful shutdown
process.on('SIGTERM', () => {
  log('ðŸ›‘ Received SIGTERM, shutting down gracefully...', 'yellow');
  process.exit(0);
});

process.on('SIGINT', () => {
  log('ðŸ›‘ Received SIGINT, shutting down gracefully...', 'yellow');
  process.exit(0);
});

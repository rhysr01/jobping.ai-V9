name: Automated Job Scraping

on:
  schedule:
    # Runs at 08:00 and 18:00 UTC every day (2x daily)
    - cron: '0 8,18 * * *'
  
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      scrapers:
        description: 'Scrapers to run (comma-separated: adzuna, jobspy, reed, orchestrator)'
        required: false
        default: 'orchestrator'
        type: string
      city:
        description: 'City for location-specific scraping'
        required: false
        default: ''
        type: string

concurrency:
  group: scrape
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120 # Prevent hanging runs
    # Estimated total time: JobSpy (~20min) + Adzuna (~15min) + Reed (~10min) + CareerJet (~15min) + Arbeitnow (~17min) = ~77min
    # 120min timeout provides comfortable buffer. Google Jobs removed due to 429 rate limiting.
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js (LTS)
      uses: actions/setup-node@v4
      with:
        node-version: '20'  # Use LTS instead of 24
        cache: 'npm'

    - name: Setup Python 3.11 (for JobSpy)
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Verify requirements file exists
      run: |
        if [ ! -f "scripts/python-requirements.txt" ]; then
          echo "‚ùå Error: scripts/python-requirements.txt not found after checkout"
          echo "Current directory: $(pwd)"
          echo "Repository contents:"
          ls -la
          echo "Scripts directory contents:"
          ls -la scripts/ 2>&1 || echo "scripts/ directory not found"
          exit 1
        fi
        echo "‚úÖ Requirements file found: scripts/python-requirements.txt"

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('scripts/python-requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python deps (JobSpy)
      run: |
        python -m pip install --upgrade pip
        python -m pip install -r scripts/python-requirements.txt
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate required secrets
      run: |
        # Store secrets in variables first to avoid evaluation issues
        # Use NEXT_PUBLIC_SUPABASE_URL if SUPABASE_URL is not set (backward compatibility)
        SUPABASE_URL="${{ secrets.SUPABASE_URL || secrets.NEXT_PUBLIC_SUPABASE_URL }}"
        SUPABASE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
        
        # Debug: Check if secrets are accessible (without exposing values)
        echo "üîç Checking secrets..."
        if [ -z "$SUPABASE_URL" ]; then
          echo "‚ùå SUPABASE_URL or NEXT_PUBLIC_SUPABASE_URL secret is missing or empty"
          echo "üí° Check: Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí SUPABASE_URL or NEXT_PUBLIC_SUPABASE_URL"
          exit 1
        else
          echo "‚úÖ SUPABASE_URL is set (length: ${#SUPABASE_URL} chars)"
        fi
        
        if [ -z "$SUPABASE_KEY" ]; then
          echo "‚ùå SUPABASE_SERVICE_ROLE_KEY secret is missing or empty"
          echo "üí° Check: Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí SUPABASE_SERVICE_ROLE_KEY"
          exit 1
        else
          echo "‚úÖ SUPABASE_SERVICE_ROLE_KEY is set (length: ${#SUPABASE_KEY} chars)"
        fi
        
        # Optional secrets (warn only)
        if [ -z "${{ secrets.ADZUNA_APP_ID }}" ]; then
          echo "‚ö†Ô∏è  ADZUNA_APP_ID secret is missing (Adzuna scraper will skip)"
          echo "   üîó Get credentials: https://developer.adzuna.com/"
        else
          echo "‚úÖ ADZUNA_APP_ID is set"
        fi

        if [ -z "${{ secrets.ADZUNA_APP_KEY }}" ]; then
          echo "‚ö†Ô∏è  ADZUNA_APP_KEY secret is missing (Adzuna scraper will skip)"
          echo "   üîó Get credentials: https://developer.adzuna.com/"
        else
          echo "‚úÖ ADZUNA_APP_KEY is set"
        fi

        if [ -z "${{ secrets.REED_API_KEY }}" ]; then
          echo "‚ö†Ô∏è  REED_API_KEY secret is missing (Reed scraper will skip)"
        else
          echo "‚úÖ REED_API_KEY is set"
        fi
        
        if [ -z "${{ secrets.JOOBLE_API_KEY }}" ]; then
          echo "‚ö†Ô∏è  JOOBLE_API_KEY secret is missing (Jooble scraper will skip)"
        else
          echo "‚úÖ JOOBLE_API_KEY is set"
        fi
        
        echo "‚úÖ Required secrets validated"

        # Test Adzuna credentials if present
        if [ -n "${{ secrets.ADZUNA_APP_ID }}" ] && [ -n "${{ secrets.ADZUNA_APP_KEY }}" ]; then
          echo "üîç Testing Adzuna API credentials..."
          # Simple curl test to validate credentials
          TEST_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null "https://api.adzuna.com/v1/api/jobs/gb/search/1?app_id=${{ secrets.ADZUNA_APP_ID }}&app_key=${{ secrets.ADZUNA_APP_KEY }}&what=developer&results_per_page=1")
          if [ "$TEST_RESPONSE" = "200" ]; then
            echo "‚úÖ Adzuna API credentials are valid"
          else
            echo "‚ùå Adzuna API credentials are INVALID (HTTP $TEST_RESPONSE)"
            echo "   üìù Please update ADZUNA_APP_ID and ADZUNA_APP_KEY in GitHub secrets"
            echo "   üîó Renew credentials: https://developer.adzuna.com/"
            echo "   üí° The workflow will continue but Adzuna scraping will be skipped"
          fi
        fi
      
    - name: Run scraping
      env:
        # Database (from secrets, not hardcoded)
        # Use NEXT_PUBLIC_SUPABASE_URL if SUPABASE_URL is not set (backward compatibility)
        NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL || secrets.NEXT_PUBLIC_SUPABASE_URL }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL || secrets.NEXT_PUBLIC_SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        
        # API Keys
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ADZUNA_APP_ID: ${{ secrets.ADZUNA_APP_ID }}
        ADZUNA_APP_KEY: ${{ secrets.ADZUNA_APP_KEY }}
        REED_API_KEY: ${{ secrets.REED_API_KEY }}
        CAREERJET_API_KEY: ${{ secrets.CAREERJET_API_KEY }}
        JOOBLE_API_KEY: ${{ secrets.JOOBLE_API_KEY }}
        MUSE_API_KEY: ${{ secrets.MUSE_API_KEY }}
        RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
        JOBPING_API_KEY: ${{ secrets.JOBPING_API_KEY }}
        
        # Scraper Configuration
        SCRAPER_CYCLE_JOB_TARGET: 5000
        JOB_TTL_DAYS: 10

        # OPTIMIZED: Reduce EU scraper load to prevent timeouts
        CAREERJET_MAX_PAGES: 3
        JOOBLE_MAX_REQUESTS: 100
        ARBEITNOW_MAX_REQUESTS: 50
        
        # Environment
        NODE_ENV: production
        JOBPING_PRODUCTION_MODE: 'true'
        GITHUB_ACTIONS: 'true' # Ensures single-run mode
        CITY: ${{ github.event.inputs.city }}
        PYTHON: python
      run: |
        set -e  # Exit on error
        set -o pipefail  # Catch errors in pipes
        
        echo "üöÄ Starting JobPing scraping..."
        SCRAPERS_INPUT="${{ github.event.inputs.scrapers }}"
        
        if [ -z "$SCRAPERS_INPUT" ] || [ "$SCRAPERS_INPUT" = "orchestrator" ]; then
          echo "‚ñ∂Ô∏è Running streamlined orchestrator (all scrapers via real-job-runner)"
          node automation/real-job-runner.cjs --single-run
        else
          IFS=',' read -ra NAMES <<< "$SCRAPERS_INPUT"
          for s in "${NAMES[@]}"; do
            case "$s" in
              adzuna)
                echo "‚ñ∂Ô∏è Running Adzuna wrapper (CITY=$CITY)"
                if [ -n "$CITY" ]; then 
                  CITY="$CITY" node scrapers/wrappers/adzuna-wrapper.cjs
                else 
                  node scrapers/wrappers/adzuna-wrapper.cjs
                fi
                ;;
              jobspy)
                echo "‚ñ∂Ô∏è Running JobSpy wrapper"
                node scrapers/wrappers/jobspy-wrapper.cjs
                ;;
              reed)
                echo "‚ñ∂Ô∏è Running Reed wrapper"
                node scrapers/wrappers/reed-wrapper.cjs
                ;;
              *)
                echo "‚ùì Unknown scraper: $s (supported: adzuna, jobspy, reed, orchestrator)"
                exit 1
                ;;
            esac
          done
        fi

    - name: Upload logs (on failure)
      if: failure()
      uses: actions/upload-artifact@v6
      with:
        name: scraper-logs-${{ github.run_id }}
        path: |
          *.log
          logs/
        retention-days: 7

    # Note: Cleanup is already handled by real-job-runner.cjs (deactivateStaleJobs)
    # The separate cleanup job was removed as it's redundant

    # Add troubleshooting information
    - name: Troubleshooting Info
      if: failure()
      run: |
        echo "üîß TROUBLESHOOTING GUIDANCE:"
        echo ""
        echo "1. ADZUNA API CREDENTIALS:"
        echo "   - If Adzuna fails with HTTP 401, credentials are expired/invalid"
        echo "   - Go to: https://developer.adzuna.com/"
        echo "   - Update ADZUNA_APP_ID and ADZUNA_APP_KEY in GitHub secrets"
        echo ""
        echo "2. EU SCRAPER TIMEOUTS:"
        echo "   - CareerJet, Arbeitnow, Jooble timing out after 2-3 minutes"
        echo "   - This is expected due to API limits and network latency"
        echo "   - The workflow continues with other scrapers (JobSpy, Reed)"
        echo ""
        echo "3. JOB VALIDATION ISSUES:"
        echo "   - Some jobs missing title/company/job_url fields"
        echo "   - This is normal - invalid jobs are filtered out automatically"
        echo ""
        echo "4. WORKFLOW SUCCESS:"
        echo "   - Even with some scraper failures, the workflow succeeds if at least one scraper works"
        echo "   - Check the final stats for actual jobs processed"

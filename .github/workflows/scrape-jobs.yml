name: Automated Job Scraping

on:
  schedule:
    # Runs at 08:00 and 18:00 UTC every day (2x daily)
    - cron: '0 8,18 * * *'
  
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      scrapers:
        description: 'Scrapers to run (comma-separated: adzuna, jobspy, reed, orchestrator)'
        required: false
        default: 'orchestrator'
        type: string
      city:
        description: 'City for location-specific scraping'
        required: false
        default: ''
        type: string

concurrency:
  group: scrape
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120 # Prevent hanging runs
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js (LTS)
      uses: actions/setup-node@v4
      with:
        node-version: '20'  # Use LTS instead of 24
        cache: 'npm'

    - name: Setup Python 3.11 (for JobSpy)
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('scripts/python-requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python deps (JobSpy)
      run: |
        python -m pip install --upgrade pip
        python -m pip install -r scripts/python-requirements.txt
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate required secrets
      run: |
        if [ -z "${{ secrets.SUPABASE_URL }}" ]; then
          echo "‚ùå SUPABASE_URL secret is missing"
          exit 1
        fi
        if [ -z "${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" ]; then
          echo "‚ùå SUPABASE_SERVICE_ROLE_KEY secret is missing"
          exit 1
        fi
        if [ -z "${{ secrets.ADZUNA_APP_ID }}" ]; then
          echo "‚ö†Ô∏è  ADZUNA_APP_ID secret is missing (Adzuna scraper will fail)"
        fi
        if [ -z "${{ secrets.REED_API_KEY }}" ]; then
          echo "‚ö†Ô∏è  REED_API_KEY secret is missing (Reed scraper will fail)"
        fi
        echo "‚úÖ Required secrets validated"
      
    - name: Run scraping
      env:
        # Database (from secrets, not hardcoded)
        NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        
        # API Keys
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ADZUNA_APP_ID: ${{ secrets.ADZUNA_APP_ID }}
        ADZUNA_APP_KEY: ${{ secrets.ADZUNA_APP_KEY }}
        REED_API_KEY: ${{ secrets.REED_API_KEY }}
        CAREERJET_API_KEY: ${{ secrets.CAREERJET_API_KEY }}
        MUSE_API_KEY: ${{ secrets.MUSE_API_KEY }}
        RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
        JOBPING_API_KEY: ${{ secrets.JOBPING_API_KEY }}
        
        # Scraper Configuration
        SCRAPER_CYCLE_JOB_TARGET: 5000
        JOB_TTL_DAYS: 10
        
        # Environment
        NODE_ENV: production
        JOBPING_PRODUCTION_MODE: 'true'
        GITHUB_ACTIONS: 'true' # Ensures single-run mode
        CITY: ${{ github.event.inputs.city }}
        PYTHON: python
      run: |
        set -e  # Exit on error
        set -o pipefail  # Catch errors in pipes
        
        echo "üöÄ Starting JobPing scraping..."
        SCRAPERS_INPUT="${{ github.event.inputs.scrapers }}"
        
        if [ -z "$SCRAPERS_INPUT" ] || [ "$SCRAPERS_INPUT" = "orchestrator" ]; then
          echo "‚ñ∂Ô∏è Running streamlined orchestrator (all scrapers via real-job-runner)"
          node automation/real-job-runner.cjs --single-run
        else
          IFS=',' read -ra NAMES <<< "$SCRAPERS_INPUT"
          for s in "${NAMES[@]}"; do
            case "$s" in
              adzuna)
                echo "‚ñ∂Ô∏è Running Adzuna wrapper (CITY=$CITY)"
                if [ -n "$CITY" ]; then 
                  CITY="$CITY" node scrapers/wrappers/adzuna-wrapper.cjs
                else 
                  node scrapers/wrappers/adzuna-wrapper.cjs
                fi
                ;;
              jobspy)
                echo "‚ñ∂Ô∏è Running JobSpy wrapper"
                node scrapers/wrappers/jobspy-wrapper.cjs
                ;;
              reed)
                echo "‚ñ∂Ô∏è Running Reed wrapper"
                node scrapers/wrappers/reed-wrapper.cjs
                ;;
              *)
                echo "‚ùì Unknown scraper: $s (supported: adzuna, jobspy, reed, orchestrator)"
                exit 1
                ;;
            esac
          done
        fi

    - name: Upload logs (on failure)
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: scraper-logs-${{ github.run_id }}
        path: |
          *.log
          logs/
        retention-days: 7

    # Note: Cleanup is already handled by real-job-runner.cjs (deactivateStaleJobs)
    # The separate cleanup job was removed as it's redundant
